## üìå Sobre o Projeto

Este projeto cont√©m um programa em **MPI (Message Passing Interface)** que divide um vetor entre v√°rios processos, distribui o trabalho e coleta as somas parciais enviadas pelos processos trabalhadores.

O programa utiliza o modelo de **paralelismo distribu√≠do**, no qual cada processo tem sua pr√≥pria mem√≥ria e precisa trocar mensagens para cooperar.

---

# üß™ Como Compilar e Executar

## ‚úî Pr√©-requisitos

Instale MPI no Linux:

```bash
sudo apt install mpich
```

ou

```bash
sudo apt install openmpi-bin libopenmpi-dev
```

Verifique:

```bash
mpic++ --version
mpirun --version
```

---

## ‚úî Compilar o c√≥digo

Supondo que o arquivo se chame `trabalho.cpp`:

```bash
mpic++ trabalho.cpp -o trabalho
```

Isso criar√° um execut√°vel chamado **trabalho**.

---

## ‚úî Executar o programa

Execute com pelo menos **2 processos** (1 mestre + 1 trabalhador):

```bash
mpirun -np 4 ./trabalho
```

Exemplo com 4 processos:

* Processo 0 = Mestre
* Processos 1, 2, 3 = Trabalhadores

---

# üß† Diferen√ßa entre MPI e OpenMP

O projeto usa **MPI**, mas √© importante entender como ele se diferencia do **OpenMP**, outro modelo popular de paralelismo.

---

# üüß MPI (OpenMPI / MPICH)

### ‚úî Modelo: **Mem√≥ria distribu√≠da**

Cada processo tem sua **pr√≥pria mem√≥ria**, e a comunica√ß√£o √© feita atrav√©s de **mensagens**:

* `MPI_Send`
* `MPI_Recv`
* `MPI_Bcast`, etc.

### ‚úî Uso t√≠pico:

* Clusters e supercomputadores
* Computadores conectados em rede
* Sistemas com m√∫ltiplas m√°quinas f√≠sicas

### ‚úî Caracter√≠sticas:

* Escala muito bem (centenas ou milhares de n√≥s)
* Comunica√ß√£o expl√≠cita
* Programa√ß√£o mais complexa

---

# üü¶ OpenMP

### ‚úî Modelo: **Mem√≥ria compartilhada**

Todos os threads compartilham a **mesma mem√≥ria RAM**.

Exemplo:

```cpp
#pragma omp parallel for
for (int i = 0; i < N; i++)
    a[i] = b[i] + c[i];
```

### ‚úî Uso t√≠pico:

* Uma √∫nica m√°quina com v√°rios n√∫cleos
* Paralelizar loops e se√ß√µes de c√≥digo

### ‚úî Caracter√≠sticas:

* F√°cil de usar
* N√£o funciona entre m√°quinas diferentes
* N√£o envolve envio de mensagens

---

# üìå Resumo

* **OpenMP** ‚Üí para paralelizar em *uma √∫nica m√°quina*.
* **MPI** ‚Üí para paralelizar em *v√°rias m√°quinas ou processos independentes*.
* Este projeto usa **MPI** porque cada processo executa isolado e troca mensagens com o mestre.

---

# ‚úî Quer que eu adicione um diagrama ou imagem explicando o fluxo mestre/trabalhadores?

Posso incluir tamb√©m exemplos de sa√≠da, instru√ß√µes para clusters SLURM, ou uma se√ß√£o ‚ÄúComo funciona o c√≥digo internamente‚Äù.
